1. How long did your reddit_averages.py take with (1) the reddit-0 data set and effectively no work, (2) no schema specified and not caching 
(on reddit-2 for this and the rest), (3) with a schema but not caching, (4) with both a schema and caching the twice-used DataFrame? [The 
reddit-0 test is effectively measuring the Spark startup time, so we can see how long it takes to do the actual work on reddit-2 in the best/
worst cases.]
A. 

2. Based on the above, does it look like most of the time taken to process the reddit-2 data set is in reading the files, or calculating the 
averages?
A. 

3. Where did you use .cache() in your wikipedia_popular.py? [Hint: the answer had better be “once”… but where?]
A.